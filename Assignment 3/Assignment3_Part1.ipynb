{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcbtLroJOcQ1",
        "outputId": "5a544e21-175c-4e1c-8804-8cd6138ed667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the IMDB dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "GA62ExAYP3S6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return tokens\n",
        "\n",
        "df['tokens'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df['sentiment'] = le.fit_transform(df['sentiment'])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['tokens'], df['sentiment'], test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxSTIuwO1jG",
        "outputId": "3c5bd334-9e7d-401d-b896-9c11b08f2a3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "id": "8rClBtjuO5Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501543ed-1564-4913-eb9a-95031db1fd8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "num_words = len(word_index) + 1\n",
        "embedding_dim = 100  # GloVe embedding dimension\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in glove:\n",
        "        embedding_matrix[i] = glove[word]\n"
      ],
      "metadata": {
        "id": "Pfbm9HCLok9Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=100, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=100, padding='post')\n"
      ],
      "metadata": {
        "id": "aNHVD21QpO2S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_rnn = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False),\n",
        "    tf.keras.layers.SimpleRNN(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_rnn.fit(X_train_padded, y_train, epochs=10, batch_size=64, validation_data=(X_test_padded, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgxFKcFtqB3j",
        "outputId": "ae296bc5-de0a-4c82-b914-d69ecee8eeb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.5588 - loss: 0.6791 - val_accuracy: 0.5632 - val_loss: 0.6704\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6383 - loss: 0.6300 - val_accuracy: 0.6260 - val_loss: 0.6415\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6147 - loss: 0.6475 - val_accuracy: 0.6654 - val_loss: 0.6087\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6396 - loss: 0.6274 - val_accuracy: 0.6806 - val_loss: 0.5965\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.6472 - loss: 0.6247 - val_accuracy: 0.6871 - val_loss: 0.5996\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6079 - loss: 0.6519 - val_accuracy: 0.6064 - val_loss: 0.6503\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.6199 - loss: 0.6392 - val_accuracy: 0.6113 - val_loss: 0.6552\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.6364 - loss: 0.6262 - val_accuracy: 0.6231 - val_loss: 0.6389\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6264 - loss: 0.6335 - val_accuracy: 0.6527 - val_loss: 0.6127\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.6245 - loss: 0.6359 - val_accuracy: 0.6581 - val_loss: 0.6056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e101a8a2f20>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_lstm.fit(X_train_padded, y_train, epochs=10, batch_size=64, validation_data=(X_test_padded, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a00yidRqEDw",
        "outputId": "f47a60ef-9c4d-4333-e19b-0e3b65b92571"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.6447 - loss: 0.6095 - val_accuracy: 0.7874 - val_loss: 0.4581\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7897 - loss: 0.4447 - val_accuracy: 0.8196 - val_loss: 0.3954\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.3978 - val_accuracy: 0.8324 - val_loss: 0.3615\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8367 - loss: 0.3581 - val_accuracy: 0.8476 - val_loss: 0.3409\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 0.3373 - val_accuracy: 0.8464 - val_loss: 0.3448\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8596 - loss: 0.3214 - val_accuracy: 0.8572 - val_loss: 0.3242\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.8735 - loss: 0.2955 - val_accuracy: 0.8585 - val_loss: 0.3205\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8808 - loss: 0.2781 - val_accuracy: 0.8546 - val_loss: 0.3289\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8898 - loss: 0.2606 - val_accuracy: 0.8581 - val_loss: 0.3274\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.8939 - loss: 0.2543 - val_accuracy: 0.8572 - val_loss: 0.3313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e0f82eed270>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Convert text to indices\n",
        "vocab_size = len(word_index) + 1\n",
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Padding sequences\n",
        "X_train_padded = pad_sequences(X_train_indices, maxlen=100, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_indices, maxlen=100, padding='post')\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(X_train_padded), torch.tensor(y_train.values))\n",
        "test_data = TensorDataset(torch.tensor(X_test_padded), torch.tensor(y_test.values))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "46MVph4gqHTH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "rnn_model = RNNModel(vocab_size=vocab_size, embedding_dim=100, hidden_dim=64, output_dim=1)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    rnn_model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = rnn_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "bwCPXFFXqJtH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x\n",
        "\n",
        "lstm_model = LSTMModel(vocab_size=vocab_size, embedding_dim=100, hidden_dim=64, output_dim=1)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    lstm_model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = lstm_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "Yg3jqmGDqKiW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "rnn_test_loss, rnn_test_acc = model_rnn.evaluate(X_test_padded, y_test)\n",
        "print(f\"Vanilla RNN with GloVe Embeddings - Test Loss: {rnn_test_loss}, Test Accuracy: {rnn_test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiCT8U9KqgJI",
        "outputId": "f9f05bf5-e636-41b7-de32-15507276f9e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6584 - loss: 0.6023\n",
            "Vanilla RNN with GloVe Embeddings - Test Loss: 0.6055726408958435, Test Accuracy: 0.6581000089645386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set\n",
        "lstm_test_loss, lstm_test_acc = model_lstm.evaluate(X_test_padded, y_test)\n",
        "print(f\"LSTM with GloVe Embeddings - Test Loss: {lstm_test_loss}, Test Accuracy: {lstm_test_acc}\")\n"
      ],
      "metadata": {
        "id": "MY_gSeDtzdF4",
        "outputId": "781549ab-e57a-4104-9fc0-5aba8dd4791b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3272\n",
            "LSTM with GloVe Embeddings - Test Loss: 0.33133894205093384, Test Accuracy: 0.857200026512146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "rnn_test_acc = evaluate_model(rnn_model, test_loader)\n",
        "print(f\"Vanilla RNN with On-the-Fly Embeddings - Test Accuracy: {rnn_test_acc}\")\n"
      ],
      "metadata": {
        "id": "rcnO5YhxzgxA",
        "outputId": "eb951686-a552-41ae-b427-9ccca613b038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla RNN with On-the-Fly Embeddings - Test Accuracy: 0.7788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_test_acc = evaluate_model(lstm_model, test_loader)\n",
        "print(f\"LSTM with On-the-Fly Embeddings - Test Accuracy: {lstm_test_acc}\")\n"
      ],
      "metadata": {
        "id": "f92DZLjvzjNI",
        "outputId": "4312b97f-637d-4507-f8a8-416b2a28a019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM with On-the-Fly Embeddings - Test Accuracy: 0.8466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Comparison of Models\")\n",
        "print(\"---------------------\")\n",
        "print(f\"Vanilla RNN with GloVe Embeddings - Test Accuracy: {rnn_test_acc}, Test Loss: {rnn_test_loss}\")\n",
        "print(f\"LSTM with GloVe Embeddings - Test Accuracy: {lstm_test_acc}, Test Loss: {lstm_test_loss}\")\n",
        "print(f\"Vanilla RNN with On-the-Fly Embeddings - Test Accuracy: {rnn_test_acc}\")\n",
        "print(f\"LSTM with On-the-Fly Embeddings - Test Accuracy: {lstm_test_acc}\")\n"
      ],
      "metadata": {
        "id": "DAGXDgl6zlcv",
        "outputId": "6a9e6742-27e5-431b-d283-375c3dff1aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison of Models\n",
            "---------------------\n",
            "Vanilla RNN with GloVe Embeddings - Test Accuracy: 0.7788, Test Loss: 0.6055726408958435\n",
            "LSTM with GloVe Embeddings - Test Accuracy: 0.8466, Test Loss: 0.33133894205093384\n",
            "Vanilla RNN with On-the-Fly Embeddings - Test Accuracy: 0.7788\n",
            "LSTM with On-the-Fly Embeddings - Test Accuracy: 0.8466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWw93j4Czn5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}